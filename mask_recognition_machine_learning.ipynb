{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook contains code to train mask classifiers the compiled image dataset\n",
    "\n",
    "Face Analysis\n",
    "* [Feature Extraction](#feat_ext)\n",
    "* [Machine Learning Classifiers](#ml) \n",
    "* [Deep Learning with Keras](#dl)\n",
    "\n",
    "Face Analysis with Additional Mask Annotation\n",
    "* TODO: need to complete this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN # TODO: what is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Image Data and Labels from the Compiled Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('compiled_labels_km-annotated.csv')\n",
    "\n",
    "display(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Some Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def plot_image_with_all_bboxes(img_nm):\n",
    "    dat = train[train['name'] == img_nm]\n",
    "    print(img_nm,\"has\",len(dat),'label(s)')\n",
    "    print(dat['image_file_dir']+img_nm)\n",
    "    \n",
    "    img = cv2.imread(dat.iloc[0]['image_file_dir']+img_nm,cv2.IMREAD_GRAYSCALE)\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "    class_name_ls = []\n",
    "    for index,row in dat.iterrows():\n",
    "        rect = patches.Rectangle(\n",
    "            (row['x1'],row['x2']),\n",
    "            row['y1'],\n",
    "            row['y2'],\n",
    "            linewidth=2,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(row['y2']-50, row['y2']-50, row['classname'], fontsize=12,color='r',fontweight='bold')\n",
    "        class_name_ls.append(row['classname'])\n",
    "    print(class_name_ls)\n",
    "    plt.show()\n",
    "name_ls =list(set(train['name']))\n",
    "random.shuffle(name_ls)\n",
    "\n",
    "for f in name_ls[0:10]:\n",
    "    plot_image_with_all_bboxes(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Distribution of the Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.classname.value_counts().plot(kind='bar')\n",
    "print(train.classname.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get only training data corresponding faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "train_face = train[train['classname'] != 'face_mask']\n",
    "# Drop annotations for label face_other_covering\n",
    "train_face = train_face[train_face['classname']!='face_other_covering']\n",
    "train_face = train_face.reset_index()\n",
    "display(train_face)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(train_face['classname']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feat_ext'></a>\n",
    "# Extract only faces from images\n",
    "(This may take several minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracts images and places the information into a list (data) of 50x50 pixel images\n",
    "img_size=224#50\n",
    "data=[]\n",
    "path=\"../Dataset/compiled_data/\"\n",
    "to_drop = []\n",
    "    \n",
    "for index,row in train_face.iterrows(): # only extract face annotation (NOT mask annotations)\n",
    "    # reads in the image and converts it to greyscale \n",
    "    img_array=cv2.imread(row['image_file_dir']+row['name'],cv2.IMREAD_GRAYSCALE)#\n",
    "    # crops the image to only include the face \n",
    "    crop_image = img_array[row['x2']:(row['y2']+row['x2']),\n",
    "                           row['x1']:(row['y1']+row['x1'])]\n",
    "    # resizes the image to 50x50\n",
    "    try:\n",
    "        new_img_array=cv2.resize(crop_image,(img_size,img_size))\n",
    "    #         plt.imshow(new_img_array)\n",
    "    #         plt.show()\n",
    "        data.append([new_img_array,row['classname']])#new_img_array[1]])\n",
    "    except:\n",
    "        print(row['name'],\"cannot be formatted\")\n",
    "        plt.imshow(img_array)\n",
    "        plt.show()\n",
    "        # keep track of those without the appropriate information and drop from the dataframe\n",
    "        to_drop.append(index)\n",
    "        data.append(-1)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some annotations of small faces cannot be included as we cannot generate a 50x50 image with them so will exclude for now\n",
    "NOTE: other annotations of these same image files will be retained as they are valuable to our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Some Extracted Faces\n",
    "two from each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get INDICIES of two images from each data source\n",
    "index_ls = []\n",
    "for d in list(set(train_face['image_file_dir'])):# will be different for each dataset\n",
    "    index_ls+=list(train_face[train_face['image_file_dir'] == d].index)[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show a few extracted faces:\n",
    "for i in index_ls:\n",
    "    print(data[i][0])\n",
    "    print(\"Shape:\",data[i][0].shape)\n",
    "    plt.imshow(data[i][0])\n",
    "    plt.show()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop excluded annotations \n",
    "Drop elements in data that are -1 \n",
    "Drop rows in train_face with indicies in to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude annotations that could not be formatted\n",
    "train_face = train_face.drop(to_drop)\n",
    "\n",
    "initial_len = len(data)\n",
    "data = [x for x in data if x != -1]\n",
    "\n",
    "print(\"Dropped\",len(to_drop),\"images from train_face\")\n",
    "print(\"Dropped\",initial_len-len(data),\"faces from data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Labels and Features as x and y\n",
    "### Convert labels to feature vector of 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extracts labels (mask/no mask) and features (50x50 vector of face image) and places them into x and y lists respectively\n",
    "x=[]\n",
    "y=[]\n",
    "for features, labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl=LabelEncoder()\n",
    "y=lbl.fit_transform(y)\n",
    "print(\"y:\",y)\n",
    "print(\"x:\",x[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split'></a>\n",
    "### Partition Training set to use part for evaluating (because submission set is unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "sz = 0.2# 0.8 # size of test set partition\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=sz, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Full labelled dataset size:\",len(x))\n",
    "print(\"Splitting data into training/testing set with a \"+str(sz*100)+\"% partition\")\n",
    "print(\"Training set size:\",len(x_train))\n",
    "print(\"Test set size:\",len(x_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ml'></a>\n",
    "\n",
    "# ML Model Fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data For sklearn model fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "print((x_train).shape)\n",
    "x_test = np.array(x_test)\n",
    "print((x_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training 2\\\n",
    "x_train = np.array(x_train).reshape(-1,224,224)\n",
    "nsamples, nx, ny =  x_train.shape\n",
    "x_train = x_train.reshape((nsamples,nx*ny))\n",
    "# normalize data - if don't logistic regression does not converge\n",
    "from sklearn import preprocessing\n",
    "x_train = preprocessing.normalize(x_train)\n",
    "\n",
    "#testing set\n",
    "x_test = np.array(x_test).reshape(-1,224,224)#50,50)\n",
    "nsamples, nx, ny = x_test.shape\n",
    "x_test = x_test.reshape((nsamples,nx*ny))\n",
    "# normalize data - if don't logistic regression does not converge\n",
    "from sklearn import preprocessing\n",
    "x_test = preprocessing.normalize(x_test)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print()\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ls = [] # list of classifiers \n",
    "fit_ct = 0 # to monitor status of fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_ls.append(\n",
    "    LogisticRegression().fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "\n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "clf_ls.append(\n",
    "    LinearSVC().fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit classifier\n",
    "# from sklearn.svm import SVC\n",
    "# clf_ls.append(\n",
    "#     SVC(kernel='linear',probability=True).fit(x_train,y_train)\n",
    "# ) # fit and add classifier to list \n",
    "# fit_ct+=1\n",
    "# print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# # fit classifier\n",
    "# from sklearn.svm import SVC\n",
    "# clf_ls.append(\n",
    "#     SVC(kernel='rbf',probability=True).fit(x_train,y_train)\n",
    "# ) # fit and add classifier to list \n",
    "# fit_ct+=1\n",
    "# print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# # fit classifier\n",
    "# from sklearn.svm import SVC\n",
    "# clf_ls.append(\n",
    "#     SVC(kernel='poly',probability=True).fit(x_train,y_train)\n",
    "# ) # fit and add classifier to list \n",
    "# fit_ct+=1\n",
    "# print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# # fit classifier\n",
    "# from sklearn.svm import SVC\n",
    "# clf_ls.append(\n",
    "#     SVC(kernel='sigmoid',probability=True).fit(x_train,y_train)\n",
    "# ) # fit and add classifier to list \n",
    "# fit_ct+=1\n",
    "# print(\"Fitting classifier\",fit_ct,\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest-Neighbors - distance weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=2,weights='distance').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=5,weights='distance').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=2,weights='distance').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=10,weights='distance').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest-Neighbors - uniform weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=2,weights='uniform').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=5,weights='uniform').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=2,weights='uniform').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")\n",
    "\n",
    "# fit classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_ls.append(\n",
    "    KNeighborsClassifier(n_neighbors=10,weights='uniform').fit(x_train,y_train)\n",
    ") # fit and add classifier to list \n",
    "fit_ct+=1\n",
    "print(\"Fitting classifier\",fit_ct,\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_classifier(clf, x_train, y_train, x_test, y_test):\n",
    "    '''\n",
    "    Assesses the inputted classifier (clf) \n",
    "    parameters:\n",
    "        clf: sklearn classifier\n",
    "        x_train: list training features\n",
    "        y_train: list of training labels\n",
    "        x_test: list of features for evaluating \n",
    "        y_test: list of labels for evaluating\n",
    "    \n",
    "    prints scores on training and testing sets\n",
    "    \n",
    "    returns:\n",
    "        sc_train: score of classifier on training set\n",
    "        sc_test: score of classifier on testing set\n",
    "        pred_train: list of predicted labels from training set prediction\n",
    "        pred_test: list of predicted labels from testing set prediction\n",
    "        probs_test: list of predicted class probabilities for x_test\n",
    "    '''\n",
    "    # score\n",
    "    sc_train = clf.score( x_train, y_train ) \n",
    "    sc_test  = clf.score( x_test,  y_test  ) \n",
    "\n",
    "    # predict\n",
    "    pred_train = clf.predict( x_train )\n",
    "    pred_test  = clf.predict( x_test  )\n",
    "    \n",
    "    # probabilities\n",
    "    try:\n",
    "        probs_test = clf.predict_proba( x_test)\n",
    "    except:\n",
    "        probs_test = []\n",
    "        print(clf,\"does not have probabilities\")\n",
    "    \n",
    "    # print scores \n",
    "    print(\"Score on Training set:\",sc_train)\n",
    "    print(\"Score on Testing set:\",sc_test)\n",
    "    return(sc_train, sc_test, pred_train, pred_test, probs_test)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess performance of each classifier in clf_ls\n",
    "### Plot confusion matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_score_ls = [] # 2D list of classifier scores [sc_train, sc_test]\n",
    "clf_probs_ls = [] # list of probabilities for x_test for classifiers \n",
    "clf_names_ls = [] # list of classifier names\n",
    "clf_pred_train_ls = [] # list of predicted labels for test dataset\n",
    "clf_pred_test_ls = [] # list of predicted labels for training dataset\n",
    "print(len(clf_ls),\"classifiers to assess\")\n",
    "for c in clf_ls:\n",
    "    print(\"\\nAssessing Classifier:\\n\",c)\n",
    "    clf_names_ls.append(str(c))\n",
    "    sc_train, sc_test, pred_train, pred_test, probs_test = assess_classifier(c, x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    clf_pred_train_ls.append(pred_train)\n",
    "    clf_pred_test_ls.append(pred_test)\n",
    "    \n",
    "    clf_score_ls.append([sc_train, sc_test])\n",
    "    clf_probs_ls.append(probs_test)\n",
    "\n",
    "print(\"Test set masks:\",len([x for x in y_test if x==0]))\n",
    "print(\"Test set no masks:\",   len([x for x in y_test if x==1]))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Change default matplotlib plotting paramters\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\" # set default font to Arial\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\" # ALWAYS use sans-serif fonts\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "\n",
    "\n",
    "for i in range(len(clf_pred_test_ls)):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    cm = confusion_matrix(y_test,clf_pred_test_ls[i])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(\"TN:\",tn,\" FP:\",fp,\" FN:\",fn,\" TP:\",tp)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Mask\",\"No Mask\"])\n",
    "    disp.plot(cmap='GnBu',ax=ax)\n",
    "    ax.set_title(clf_ls[i])\n",
    "    plt.savefig('plots/'+str(clf_ls[i])+\"_confusion_matrixx.png\",dpi=300,bbox_inches=\"tight\",transparent=True)\n",
    "#     plt.show()\n",
    "    \n",
    "# # TODO: plot ROC Curve\n",
    "# from sklearn import metrics\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
    "# fpr\n",
    "\n",
    "# tpr\n",
    "\n",
    "# thresholds\n",
    "# # TODO: plot Precision Recall Curve\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(len(clf_pred_test_ls)):\n",
    "    if clf_probs_ls[i] == []:\n",
    "        pass\n",
    "    else:\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, clf_probs_ls[i][:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ### Plot Data ###\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.metrics import auc\n",
    "        import matplotlib\n",
    "        from matplotlib.gridspec import GridSpec\n",
    "        font = {'weight' : 'normal','size'   : 12,'family'   : \"Arial\"}\n",
    "        matplotlib.rc('font', **font)\n",
    "        fig = plt.figure()#figsize=(10,6))#(5,3.25))\n",
    "        ax = fig.add_subplot()\n",
    "        plt.plot(\n",
    "            fpr,\n",
    "            tpr,\n",
    "        #     '-o',#''.',\n",
    "            color = '#1a9ab0',\n",
    "        #     label =None,\n",
    "        #     markersize=2,\n",
    "        )\n",
    "        ax.set_title(clf_ls[i],fontsize=12)\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "        fig.set_size_inches(4.25,3.5)\n",
    "\n",
    "        # save roc curve values to csv so can plot with others later\n",
    "        data_file_out=str(clf_ls[i])+\"_roc_curve.csv\"\n",
    "        pd.DataFrame({\"fpr\":fpr,\"tpr\":tpr}).to_csv(data_file_out)\n",
    "        print(\"\\nROC curve data saved to:\",data_file_out)\n",
    "\n",
    "        ### Save Figure ###\n",
    "\n",
    "        plt.savefig('plots/'+str(clf_ls[i])+\"_roc_curve.png\",dpi=300,bbox_inches=\"tight\",transparent=True)\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "for i in range(len(clf_pred_test_ls)):\n",
    "    print(clf_ls[i])\n",
    "    d = metrics.classification_report(y_test,\n",
    "                                      [int(round(x,0)) for x in clf_pred_test_ls[i]],\n",
    "                                      output_dict = True\n",
    "                                     )\n",
    "\n",
    "    d = pd.DataFrame(d)\n",
    "    d = d.apply(lambda x: round(x,4))\n",
    "\n",
    "    display(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
